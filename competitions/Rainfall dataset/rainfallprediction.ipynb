{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "data = pd.read_csv('data/train.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Convert day of the year to month\n",
    "data['month'] = data['day'].apply(lambda x: datetime.datetime.strptime(str(x), '%j').month)\n",
    "data['month'] = np.sin(2 * np.pi * data['month'] / 12)\n",
    "\n",
    "# Display the updated dataframe\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns 'id' and 'day', and set 'rainfall' as the label column\n",
    "X = data.drop(columns=['id', 'day', 'rainfall'])\n",
    "y = data['rainfall']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Initialize the StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Fit and transform X\n",
    "# X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the resulting datasets\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "# from imblearn.combine import SMOTEENN\n",
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# # Handle class imbalance\n",
    "# # Combination of over- and under-sampling using SMOTEENN\n",
    "\n",
    "\n",
    "# smoteenn = SMOTEENN(random_state=42)\n",
    "# X_train_resampled, y_train_resampled = smoteenn.fit_resample(X_train, y_train)\n",
    "\n",
    "# # Define models\n",
    "# models = {\n",
    "#     \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "#     \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "# }\n",
    "\n",
    "# # Train and validate each model\n",
    "# for name, model in models.items():\n",
    "#     model.fit(X_train_resampled, y_train_resampled)\n",
    "#     y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "#     auc_score = roc_auc_score(y_test, y_test_pred_proba)\n",
    "#     print(f\"Model: {name}\")\n",
    "#     print(f\"AUC-ROC Score: {auc_score:.4f}\")\n",
    "#     print(\"-\" * 50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.ensemble import VotingClassifier\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# # Perform hyperparameter tuning for the top 3 models\n",
    "# tuned_models = {}\n",
    "# param_grids = {\n",
    "#     \"Random Forest\": {\n",
    "#         \"n_estimators\": [100, 200],\n",
    "#         \"max_depth\": [None, 10, 20],\n",
    "#         \"min_samples_split\": [2, 5],\n",
    "#     },\n",
    "#     \"Gradient Boosting\": {\n",
    "#         \"n_estimators\": [100, 200],\n",
    "#         \"learning_rate\": [0.1, 0.01],\n",
    "#         \"max_depth\": [3, 5],\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# for name, model in list(models.items()):\n",
    "#     print(f\"Tuning {name}...\")\n",
    "#     grid_search = GridSearchCV(model, param_grids[name], scoring=\"f1_weighted\", cv=3, n_jobs=-1)\n",
    "#     grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "#     tuned_models[name] = grid_search.best_estimator_\n",
    "#     print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from ndf import train_neural_forest_binary\n",
    "import torch\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y.values, dtype=torch.float32)  # Use long for classification labels\n",
    "\n",
    "ndf_model, _, metrics = train_neural_forest_binary(X_tensor, y_tensor, input_dim=11)\n",
    "\n",
    "# Display the metrics\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Create an ensemble model using the tuned models\n",
    "\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=list(tuned_models.items()),\n",
    "    voting=\"soft\"\n",
    ")\n",
    "ensemble_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Step 4: Test the ensemble model on the test set\n",
    "y_test_pred = ensemble_model.predict(X_test)\n",
    "# Calculate and display the AUC-ROC score for the ensemble model\n",
    "y_test_pred_proba = ensemble_model.predict_proba(X_test)[:, 1]\n",
    "auc_score = roc_auc_score(y_test, y_test_pred_proba)\n",
    "print(f\"\\nEnsemble Model AUC-ROC Score on Test Set: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Read the test data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwinddirection\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwinddirection\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(), inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Extract the 'id' column for the submission file\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Read the test data\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "test_data['winddirection'].fillna(test_data['winddirection'].mean(), inplace=True)\n",
    "\n",
    "# Extract the 'id' column for the submission file\n",
    "test_ids = test_data['id']\n",
    "\n",
    "# Drop unnecessary columns to match the training features\n",
    "# Ensure the columns 'id' and 'day' exist before dropping them\n",
    "if 'id' in test_data.columns and 'day' in test_data.columns:\n",
    "    X_test_final = test_data.drop(columns=['id', 'day'])\n",
    "else:\n",
    "    raise ValueError(\"The columns 'id' and 'day' are missing from the test dataset.\")\n",
    "\n",
    "# Predict the probability of rainfall using the ensemble model\n",
    "rainfall_probabilities = ensemble_model.predict_proba(X_test_final)[:, 1]\n",
    "\n",
    "# Create the submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'rainfall': rainfall_probabilities\n",
    "})\n",
    "\n",
    "# Write the submission to a CSV file\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file 'submission.csv' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
